\documentclass[11pt]{article}

\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{url}
\usepackage{wrapfig}
\usepackage{color}
\usepackage{marvosym}
\usepackage{enumerate}
\usepackage{subfigure}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref} 


\oddsidemargin 0mm
\evensidemargin 5mm
\topmargin -20mm
\textheight 240mm
\textwidth 160mm




\newcommand{\vw}{{\bf w}}
\newcommand{\vx}{{\bf x}}
\newcommand{\vy}{{\bf y}}
\newcommand{\vxi}{{\bf x}_i}
\newcommand{\yi}{y_i}
\newcommand{\vxj}{{\bf x}_j}
\newcommand{\vxnj}{{\bf x}_{n,j}}
\newcommand{\vxn}{{\bf x}_n}
\newcommand{\yj}{y_j}
\newcommand{\ai}{\alpha_i}
\newcommand{\aj}{\alpha_j}
\newcommand{\X}{{\bf X}}
\newcommand{\Y}{{\bf Y}}
\newcommand{\vz}{{\bf z}}
\newcommand{\msigma}{{\bf \Sigma}}
\newcommand{\vmu}{{\bf \mu}}
\newcommand{\vmuk}{{\bf \mu}_k}
\newcommand{\vmukj}{{\bf \mu}_{k,j}}
\newcommand{\msigmak}{{\bf \Sigma}_k}
\newcommand{\msigmakj}{{\bf \Sigma}_{k,j}}
\newcommand{\vmuj}{{\bf \mu}_j}
\newcommand{\msigmaj}{{\bf \Sigma}_j}
\newcommand{\pij}{\pi_j}
\newcommand{\pik}{\pi_k}
\newcommand{\D}{\mathcal{D}}
\newcommand{\el}{\mathcal{L}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\vxij}{{\bf x}_{ij}}
\newcommand{\vt}{{\bf t}}
\newcommand{\yh}{\hat{y}}
\newcommand{\code}[1]{{\footnotesize \tt #1}}
\newcommand{\alphai}{\alpha_i}

\pagestyle{myheadings} 
\markboth{Homework 8}{Fall 2012 CS 475 Machine Learning: Homework 8} 


\title{CS 475 Machine Learning: Homework 8\\Graphical Models \\
\Large{Due: Thursday December 6, 2012, 12:00pm}\\
50 Points Total \hspace{1cm} Version 1.0}

\author{}
\date{}

\begin{document}
\large
\maketitle
\thispagestyle{headings}

\vspace{-.5in}

\section{Programming (25 points)}
In this assignment you will implement the sum product algorithm for calculating marginal probabilities in a linear chain MRF (more specifically, a factor graph). You will implement sum product on top of potential functions that we give you (there is no learning in the homework, only exact inference).

\subsection{The Factor Graph} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\factorsize}{1}
\newcommand{\nodesize}{1.3}
\begin{figure}[h]
	\begin{center}
\begin{tikzpicture}[style=thick,scale=1] 
			\begin{scope}[shape=circle,minimum size=0.1cm] 
			\tikzstyle{every node}=[draw,fill] 
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_1) at (0,1.5) {$\mathbf{f_{1}}$};
			\node[fill=none,scale=\nodesize] (X_1) at (0,0) {$\mathbf{X_1}$};
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_N1) at (2,0) {$\mathbf{f_{n+1}}$};
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_2) at (4,1.5) {$\mathbf{f_{2}}$};
			\node[fill=none,scale=\nodesize] (X_2) at (4,0) {$\mathbf{X_2}$};
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_N2) at (6,0) {$\mathbf{f_{n+2}}$};
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_3) at (8,1.5) {$\mathbf{f_{\ldots}}$};
			\node[fill=none,scale=\nodesize] (X_3) at (8,0) {$\mathbf{...}$};
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_N3) at (10,0) {$\mathbf{f_{2n-1}}$};
			\node[fill=red,scale= \factorsize,shape=rectangle] (F_4) at (12,1.5) {$\mathbf{f_{n}}$};
			\node[fill=none,scale=\nodesize] (X_4) at (12,0) {$\mathbf{X_n}$};
			\draw [-] (X_1) -- (F_1);
			\draw [-] (X_2) -- (F_2);
			\draw [-] (X_3) -- (F_3);
			\draw [-] (X_4) -- (F_4);
			\draw [-] (X_1) -- (F_N1);
			\draw [-] (F_N1) -- (X_2);
			\draw [-] (X_2) -- (F_N2);
			\draw [-] (F_N2) -- (X_3);
			\draw [-] (X_3) -- (F_N3);
			\draw [-] (F_N3) -- (X_4);
			\end{scope} 
		\end{tikzpicture}
		\caption{The factor graph that will be used in this assignment}
			\label{fig:factor_graph}
		\end{center}
\end{figure}
Each of the variables in our chain (the $x_i$) are $k$-ary discrete variables.


\subsection{Sum Product Algorithm} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The following is adapted from section 8.4.4 of Bishop. For more details and diagrams, see the book (\href{http://research.microsoft.com/en-us/um/people/cmbishop/prml/Bishop-PRML-sample.pdf}{available online here}).

Our goal is to find the marginal probability of a node in our factor graph. Due to the linear structure of our factor graph, the sum product algorithm lets us write this marginal probability as:
\begin{equation}
	p(x) = \prod_{s \in N(x)} \Bigg[ \sum_{X_s} F_s(x, X_s) \Bigg]
\end{equation}
where:\\
\indent $N(x)$ is the set of all factor node neighbors of $x$\\
\indent $F_s(x, X_s)$ represents the product of all the factors ``downstream" of $f_s$\\
\\
Part of the above equation will be used many times, so for the sake of computation and intuition, we will define the sum term as a ``message" $\mu$:
\begin{equation}
	\mu_{f_s \rightarrow x}(x) := \sum_{X_s} F_s(x, X_s)
\end{equation}
If you look at the diagram in the book, you will see the recursive nature of $F_s(x, X_s)$, so we need a base case:
\[
	\mu_{f \rightarrow x}(x) := f(x) \text{ iff the only neighbor of f is x}
\]
\\
The sum product algorithm defines the message from a variable node to a factor node as the product of the messages it receives from its ``downstream" factors:
\begin{equation}
	\mu_{x \rightarrow f_s} := \prod_{l \in N(x) \setminus f_s} \mu_{f_l \rightarrow x}(x)
\end{equation}
\\
As before, there is a base case for this equation:
\[
	\mu_{x \rightarrow f}(x) := 1 \text{ iff the only neighbor of x is f}
\]
\\
And we're done: we can find marginal probabilities using equation 1. While seemingly simple, the details may be a bit opaque. To help clarify them, you will implement Sum Product on the chain factor graph above.


\subsection{Implementation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For the factor graph in this assignment, there are unary ($f_1$ to $f_n$) and binary ($f_{n+1}$ to $f_{2n-1}$) factors, and each factor $f_i$ is associated with a potential function $\psi_i$.
Each unary factor will have a potential function $\psi_{i}(a)$ which returns a real non-negative value corresponding to the potential when variable $x_{i}$ takes value $a$. Each factor node between two variable nodes will have a potential function $\psi_{i}(a, b)$ which returns a value corresponding to the potential when variable $x_{i-n}$ takes value $a$ and node $x_{i-n+1}$ takes value $b$. Recall that every $x_i$ can take values from $1$ to $k$.\\
\\
We will provide you code that gives you values of $\psi_i(a)$ and $\psi_i(a, b)$. They will be in the class \code{cs475.sum\_product.ChainMRFPotentials} and have the signatures:
\begin{verbatim}
    public double potential(int i, int a)
    public double potential(int i, int a, int b)
\end{verbatim}
There are $n$ nodes in this chain, so the value of \code{i} must be between 1 and $n$ (inclusive) in the first method and between $n+1$ and $2n-1$ (inclusive) in the second method. Since every $x_i$ can take values from 1 to $k$ (inclusive), you must only call this function with values for \code{a} and \code{b} between 1 and $k$ (inclusive). You will be able to get values for $n$ and $k$ by calling the following functions in \code{cs475.sum\_product.ChainMRFPotentials}:
\begin{verbatim}
    public int chainLength()  // returns n
    public int numXValues()   // returns k
\end{verbatim}
These values will be read into \code{cs475.sum\_product.ChainMRFPotentials} from a text file that must be provided in the constructor:
\begin{verbatim}
    public ChainMRFPotentials(String data_file)
\end{verbatim}
We are providing you with a sample of this data file, \code{sample\_mrf\_potentials.txt}. The format is \code{"n k"} on the first line and either \code{"i a potential"} or \code{"i a b potential"} on subsequent lines. Feel free to try out new chains to get different probability distributions, just make sure it contains all the needed potential values.\\
\\
Your code will work by calculating these messages given the value of the potential functions between the variable nodes in the chain. For details on how to do this, you can refer to your notes from class, see Bishop's examples in the book.


\subsection{What You Need to Implement} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We have provided you with a class, \code{ChainMRF}, with one method left blank that you will need to implement:
\begin{verbatim}
public class SumProduct {
    public static double[] marginalProbability(int x_i, ChainMRFPotentials p) {
        // TODO
    }
}
\end{verbatim}
This should return a double array where the $j$th element is the probability that $x_i = j$. The length of this array should be $k+1$ and you should leave the 0 index as 0. These are probabilities so don't forget to normalize to sum to 1.


\subsection{How We Will Run Your Code} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We will run your code by providing you with a single command line argument which is the data file:
\begin{verbatim}
    java cs475.sum_product.SumProductTester mrf_potentials.txt
\end{verbatim}
Note that we will use new data files with different values of $n$ and $k$, so make sure your code works for any reasonable input.\\
\\
Your output should just be the results of the print statements in the code given. {\bf Do not print anything else in the version you hand in.}


\section{Analytical Questions (25 points)}

\paragraph{1 (8 points)} Suppose you are given a markov model with $m$ variables ($x_1,x_2, \ldots x_m$) where each variable is assumed to have $k$ states ($s_1, s_2 \ldots, s_k$). You are given a $k \times k$ transition matrix $T$ with $T_{ij} = P(x_{t+1} = s_i | x_{t} = s_j)$ for $t = 1,...,m-1$. If we observe $x_1 = s_1$, please derive the probability distribution of $P(x_m)$?

\paragraph{2 (8 points)}
Consider the following Gaussian Hidden Markov Models, we have $k$ hidden states and each state has a Gaussian distribution as the output. Show the marginal distribution of the output is the Gaussian Mixture. Given some data generated by the HMM above, what is the difference between fitting Gaussian Mixture Models or Gaussian HMM?

\paragraph{3 (9 points)} You are working on a new machine learning system. After spending a lot of time collecting data, writing features and fitting a model to the data, you are disappointed in the terrible performance. You are sure there isn't a bug, but don't know what to try. You think the problem may be one of a bias and variance tradeoff.
\begin{enumerate}
\item What experiment can you run to verify if this is the case?
\item How will you determine if the problem is bias or variance?
\item Name one way to improve your system is the problem is variance.
\item Name one way to improve your system is the problem is bias.
\end{enumerate}

\section{What to Submit}
In each assignment you will submit two things.
\begin{enumerate}
\item {\bf Code:} Your code as a zip file named {\tt library.zip}. {\bf You must submit source code (.java files)}. We will run your code using the exact command lines described above, so make sure it works ahead of time. Remember to submit all of the source code, including what we have provided to you.
\item {\bf Writeup:} Your writeup as a {\bf PDF file} (compiled from latex) containing answers to the analytical questions asked in the assignment. Make sure to include your name in the writeup PDF and use the provided latex template for your answers.
\end{enumerate}

To submit your assignment, visit the ``Homework'' section of the website (\href{http://www.cs475.org/}{http://www.cs475.org/}.)

\section{Questions?}
Remember to submit questions about the assignment to the appropriate group on the class discussion board: \href{http://bb.cs475.org/}{http://bb.cs475.org}.

\end{document}


